{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /usr/local/google/home/alexanderho/.pyenv/versions/3.8.2/envs/tfx-3.8.2/lib/python3.8/site-packages (23.0.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-15 16:23:30.772084: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-15 16:23:30.945466: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-03-15 16:23:30.945498: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-03-15 16:23:32.279986: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-03-15 16:23:32.280133: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-03-15 16:23:32.280166: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.11.0\n",
      "1.12.0\n"
     ]
    }
   ],
   "source": [
    "#Check Python Version\n",
    "import shutil\n",
    "import sys\n",
    "import os\n",
    "sys.version\n",
    "\n",
    "\n",
    "#Upgrade pip\n",
    "%pip install --upgrade pip\n",
    "\n",
    "\n",
    "#Check TF & TFX Versioning\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "from tfx import v1 as tfx\n",
    "print(tfx.__version__)\n",
    "\n",
    "\n",
    "# Pipeline name\n",
    "PIPELINE_NAME = \"copy_tfrecords\"\n",
    "\n",
    "# Output directory to store artifacts generated from the pipeline.\n",
    "PIPELINE_ROOT = './artifacts'\n",
    "# Path to a SQLite DB file to use as an MLMD storage.\n",
    "METADATA_PATH = os.path.join('metadata', PIPELINE_NAME, 'metadata.db')\n",
    "# Output directory where created models from the pipeline will be exported.\n",
    "SERVING_MODEL_DIR = os.path.join('serving_model', PIPELINE_NAME)\n",
    "\n",
    "# Folder path to data\n",
    "DATA_ROOT = './data/'\n",
    "\n",
    "TFRECORDS_TRAIN_DATA_PATH = '../../../../Downloads/split_train/'\n",
    "TFRECORDS_EVAL_DATA_PATH = '../../../../Documents/split_eval/'\n",
    "TFRECORDS_GOLDEN_DATA_PATH = '../../../../Documents/split_golden/'\n",
    "\n",
    "from absl import logging\n",
    "logging.set_verbosity(logging.INFO)  # Set default logging level.\n",
    "\n",
    "import json\n",
    "import tempfile\n",
    "from typing import Any, Dict, List\n",
    "from tfx.v1.types.standard_artifacts import Examples\n",
    "from typing import Any, Dict, List, Optional, Type, Union\n",
    "\n",
    "\n",
    "from tfx.orchestration.experimental.interactive.interactive_context import InteractiveContext\n",
    "\n",
    "from tfx.dsl.component.experimental.decorators import component\n",
    "\n",
    "from tfx.dsl.io import fileio\n",
    "\n",
    "from typing import Dict, List\n",
    "from tfx.v1.types.standard_artifacts import Examples\n",
    "from typing import Dict\n",
    "\n",
    "from tfx.dsl.component.experimental.decorators import component\n",
    "\n",
    "from tfx.dsl.io import fileio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _split_names_string_builder(split_names_list: List):\n",
    "    str1 = \"[\"\n",
    "    urlist_len = len(split_names_list)-1\n",
    "    index = 0\n",
    "\n",
    "    for ele in split_names_list:\n",
    "        if(index==urlist_len):\n",
    "            str1 += \"\\\"\"+ele+\"\\\"\"+\"]\"\n",
    "            break\n",
    "        str1 += \"\\\"\"+ele+\"\\\"\"+\",\"\n",
    "        index+=1\n",
    "    return str1\n",
    "\n",
    "@component\n",
    "def CopyExampleGen(\n",
    "        input_dict: tfx.dsl.components.Parameter[Dict[str, str]],\n",
    "        output_example: tfx.dsl.components.OutputArtifact[Examples]\n",
    "      ) -> tfx.dsl.components.OutputDict():\n",
    "    \n",
    "        \"\"\"Parse input_dict: creates a directory from the split-names and tfrecord uris provided\"\"\"\n",
    "        split_names=[]\n",
    "        for key in input_dict:\n",
    "          split_names.append(key)\n",
    "          \n",
    "        split_names_string=_split_names_string_builder(split_names)\n",
    "        output_example.split_names=str(split_names_string)\n",
    "        \n",
    "        \"\"\"Make directories\"\"\"\n",
    "        tfrecords_list=[]\n",
    "        for key in input_dict:\n",
    "          split_value=\"/Split-\"+key+\"/\"\n",
    "          fileio.mkdir(output_example.uri+split_value)\n",
    "          # Are tfrecord files always going to be .gz compressed file types?\n",
    "          tfrecords_list=fileio.glob(input_dict[key]+'*.gz')\n",
    "          print(\"tfrecords_list: \" + str(tfrecords_list))\n",
    "\n",
    "          \"\"\"\"Copy files into directories\"\"\"\n",
    "          for tfrecord in tfrecords_list:\n",
    "                \"\"\"TODO: Find a better way to extra file name\"\"\"\n",
    "                file_name=os.path.basename(os.path.normpath(tfrecord))\n",
    "                fileio.copy(tfrecord, output_example.uri+split_value+file_name, True)\n",
    "                # print(\"file_name: \"+file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "from tfx.orchestration.experimental.interactive.interactive_context import InteractiveContext\n",
    "\n",
    "\"\"\"Prepare variables\"\"\"\n",
    "context=InteractiveContext()\n",
    "tfrecords_dict: Dict[str, str]={\n",
    "    \"train\":TFRECORDS_TRAIN_DATA_PATH,\n",
    "    \"eval\":TFRECORDS_EVAL_DATA_PATH,\n",
    "    \"golden\":TFRECORDS_GOLDEN_DATA_PATH\n",
    "  }\n",
    "\n",
    "\"\"\"Call CopyExampleGen Component\"\"\"\n",
    "copy_examples=CopyExampleGen(\n",
    "    input_dict=tfrecords_dict)\n",
    "\n",
    "context.run(copy_examples)\n",
    "\n",
    "\"\"\"Call StatisticsGen Component\"\"\"\n",
    "statistics_gen=tfx.components.StatisticsGen(\n",
    "    examples=copy_examples.outputs['output_example'])\n",
    "\n",
    "context.run(statistics_gen)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfx-3.8.2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
